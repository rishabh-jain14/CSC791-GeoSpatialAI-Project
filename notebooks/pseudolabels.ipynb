{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pydantic import BaseSettings\n",
    "from matplotlib import  pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsConfig(BaseSettings):\n",
    "    class Config:\n",
    "        env_file = \".env\"\n",
    "        env_file_encoding = \"utf-8\"\n",
    "    data_processed: Path\n",
    "    subset: str = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path(os.getcwd())\n",
    "os.chdir(str(cwd.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = StatsConfig()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from floods.datasets.flood import WeightedFloodDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = WeightedFloodDataset.mean()\n",
    "std = WeightedFloodDataset.std()\n",
    "\n",
    "\n",
    "# create train and validation sets\n",
    "dataset = WeightedFloodDataset(path=cfg.data_processed,\n",
    "                               subset=\"train\",\n",
    "                               include_dem=True,\n",
    "                               transform_base=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_image(image: np.ndarray, weights: tuple = (2.5, 4.0, 25.0)) -> np.ndarray:\n",
    "    vv, vh, both = weights\n",
    "    image[:,:,0] *= vv\n",
    "    image[:,:,1] *= vh\n",
    "    image[:,:,2] *= image[:,:,0] * image[:,:,1] / both\n",
    "    return np.clip(image, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_round_kernel(kernel_size: int):\n",
    "        # compute center and radius, suppose symmetrical and centered\n",
    "        center = kernel_size // 2\n",
    "        radius = min(center, kernel_size - center)\n",
    "        # compute a distance grid from the given center\n",
    "        yy, xx = np.ogrid[:kernel_size, :kernel_size]\n",
    "        dist_from_center = np.sqrt((xx - center)**2 + (yy - center)**2)\n",
    "        # produce a binary mask\n",
    "        mask = dist_from_center <= radius\n",
    "        return mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(np.random.choice(len(dataset), size=4, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [dataset[i] for i in indices]\n",
    "for image, label, weight in batches:\n",
    "    f, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    rgb = rgb_image(image, weights=(5.0, 15.0, 20.0))\n",
    "    rgb2 = cv2.medianBlur(rgb, ksize=5)\n",
    "    axes[0].imshow(rgb)\n",
    "    axes[1].imshow(rgb2)\n",
    "    axes[2].imshow(weight, vmin=0, vmax=5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy(label: np.ndarray, ignore: int = 255) -> np.ndarray:\n",
    "    valid = label.copy()\n",
    "    valid[valid == ignore] = 0\n",
    "    marg = np.histogramdd(valid.ravel(), bins = 2)[0]/label.size\n",
    "    marg = list(filter(lambda p: p > 0, np.ravel(marg)))\n",
    "    return -np.sum(np.multiply(marg, np.log2(marg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = list()\n",
    "for image, label, _ in tqdm(dataset):\n",
    "    entropies.append(entropy(label))\n",
    "\n",
    "entropies = np.array(entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies[entropies > 1] -= 1\n",
    "ranked = np.argsort(entropies)[::-1]\n",
    "n = 50\n",
    "for index in ranked[-1000:-950]:\n",
    "    img, lab, w = dataset[index]\n",
    "    f, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    axes[0].imshow(img[:,:,0] * 5, cmap=\"gray\")\n",
    "    axes[1].imshow(lab)\n",
    "    plt.tight_layout()\n",
    "    plt.title(f\"index: {index} - entropy: {entropies[index]:.4f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = np.clip(entropies, 0, 1) * 0.8 + 0.2\n",
    "# scaled = sigmoid(scaled)\n",
    "plt.plot(np.arange(len(ranked)), scaled[ranked])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test bed for weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_kernel = create_round_kernel(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.restoration import denoise_nl_means\n",
    "from skimage.morphology import opening\n",
    "\n",
    "batches = [dataset[i] for i in indices]\n",
    "for image, label in batches:\n",
    "    dem = image[:,:,-1].copy()\n",
    "    mask = label != 255\n",
    "\n",
    "    dmin = dem[mask].min()\n",
    "    dmax = dem[mask].max()\n",
    "    img = rgb_image(image)\n",
    "    denoised = denoise_nl_means(img, h = 0.1, multichannel=True)\n",
    "    flooded = ((denoised[:,:,0] <= 0.1) * (denoised[:,:,1] <= 0.1)).astype(np.uint8)\n",
    "    flooded = cv2.morphologyEx(flooded, cv2.MORPH_OPEN, morph_kernel)\n",
    "    # flooded = opening(flooded)\n",
    "    weights = flooded + label\n",
    "    f, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "    axes[0].imshow(denoised)\n",
    "    axes[1].imshow(flooded)\n",
    "    axes[2].imshow(dem)\n",
    "    axes[3].imshow(weights)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61bd0401774e7981c2ad7ca0754761d58a145d15f3fee780bc248b1d208f4211"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
