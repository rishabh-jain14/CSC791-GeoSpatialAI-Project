{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import tifffile as tif\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel, BaseSettings\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the working directory to the root dir, since we are in a subfolder\n",
    "print(os.getcwd())\n",
    "root = Path(os.getcwd()).parent.absolute()\n",
    "print(f\"Setting cwd to: {str(root)}\")\n",
    "os.chdir(str(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some models, this is a surprise tool that will help us later\n",
    "class Configuration(BaseSettings):\n",
    "    class Config:\n",
    "        env_file = '.env'\n",
    "        env_file_encoding = 'utf-8'\n",
    "    data_source: Path\n",
    "    activations_file: str\n",
    "    summary_file: str\n",
    "    countries_file: str\n",
    "    token: str\n",
    "\n",
    "\n",
    "class ActivationModel(BaseModel):\n",
    "    title: str\n",
    "    type: str\n",
    "    country: str\n",
    "    delineation: List[str]\n",
    "    start: datetime\n",
    "    end: datetime\n",
    "    lat: float = None\n",
    "    lon: float = None\n",
    "    subset: str = None\n",
    "\n",
    "\n",
    "class SARImage(BaseModel):\n",
    "    path: Path\n",
    "    code: str\n",
    "    shape: tuple\n",
    "    num_tiles: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Configuration()\n",
    "for k, v in cfg.dict().items():\n",
    "    print(f\"{k:<20s}: {str(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each activation in a pydantic model for simplicity\n",
    "activations = dict()\n",
    "\n",
    "with open(cfg.activations_file, \"r\") as f:\n",
    "    obj = json.load(f)\n",
    "    for name, value in obj.items():\n",
    "        value = {k.lower(): v for k, v in value.items()}\n",
    "        activations[name] = ActivationModel(**value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the available images based on the activation groups\n",
    "activation_groups = defaultdict(list)\n",
    "for img_file in glob(str(cfg.data_source / \"*\" / \"s1_raw\" / \"*.tif\")):\n",
    "    img_file = Path(img_file)\n",
    "    emsr_code = img_file.stem.split(\"-\")[0]\n",
    "    activation_groups[emsr_code].append(img_file)\n",
    "\n",
    "print(len(activation_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center(path: Path) -> tuple:\n",
    "    \"\"\"\n",
    "    Returns the coordinates of the center of the given image, reading the GeoTIFF from file.\n",
    "    \"\"\"\n",
    "    with rio.open(str(path), \"r\") as dataset:\n",
    "        bbox = dataset.bounds\n",
    "        center_lon = (bbox.left + bbox.right) / 2\n",
    "        center_lat = (bbox.top + bbox.bottom) / 2\n",
    "    return center_lon, center_lat\n",
    "\n",
    "\n",
    "def smooth_weights(data: np.array, smoothing: float = 0.15, clip: float = 10.0, normalize: bool = True):\n",
    "    assert smoothing >= 0 and smoothing <= 1, \"Smoothing factor out of range\"\n",
    "    if smoothing > 0:\n",
    "        # the larger the smooth factor, the bigger the quantities to sum to the remaining counts (additive smoothing)\n",
    "        smoothed_maxval = np.max(data) * smoothing\n",
    "        data += smoothed_maxval\n",
    "\n",
    "    # retrieve the (new) max value, divide by counts, round to 2 digits and clip to the given value\n",
    "    # max / value allows to keep the majority class' weights to 1, while the others will be >= 1 and <= clip\n",
    "    majority = 1.0 / np.max(data)\n",
    "    result = np.clip(np.round(data.astype(float)), a_min=0, a_max=clip)\n",
    "    if normalize:\n",
    "        result /= result.sum()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, filter out activations not present in the groups\n",
    "valid_activations = {k: v for k, v in activations.items() if k in activation_groups}\n",
    "len(valid_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emsr, image_paths in activation_groups.items():\n",
    "    # compute centers for each tiff and get average\n",
    "    centers = [get_center(p) for p in image_paths]\n",
    "    avg_center = tuple(map(lambda y: sum(y) / float(len(y)), zip(*centers)))\n",
    "    assert len(avg_center) == 2, \"it must be a tuple (lon, lat)!\"\n",
    "    # store the coords in the activation list\n",
    "    valid_activations[emsr].lon = avg_center[0]\n",
    "    valid_activations[emsr].lat = avg_center[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = defaultdict(list)\n",
    "\n",
    "for code, act in valid_activations.items():\n",
    "    df[\"code\"].append(code)\n",
    "    df[\"title\"].append(code + \" \" + act.title)\n",
    "    df[\"lon\"].append(act.lon)\n",
    "    df[\"lat\"].append(act.lat)\n",
    "    df[\"size\"].append(1)\n",
    "df = pd.DataFrame.from_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "px.set_mapbox_access_token(cfg.token)\n",
    "fig = px.scatter_mapbox(df,\n",
    "                        lat=df.lat,\n",
    "                        lon=df.lon,\n",
    "                        size=\"size\",\n",
    "                        size_max=5,\n",
    "                        hover_name=\"title\",\n",
    "                        zoom=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_files = glob(str(cfg.data_source / \"*\" / \"s1_raw\" / \"*.tif\"))\n",
    "len(sar_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 512.0\n",
    "emsr2sar = list()\n",
    "\n",
    "for path in tqdm(sar_files):\n",
    "    code = Path(path).stem.split(\"-\")[0] # extract the EMSR code\n",
    "    image = tif.imread(path) # read image and estimate tile count\n",
    "    num_tiles = (math.ceil(image.shape[0] / tile_size) * math.ceil(image.shape[1] / tile_size))\n",
    "    # create data and store into list\n",
    "    sample = SARImage(path=Path(path), code=code, shape=image.shape[:-1], num_tiles=num_tiles)\n",
    "    emsr2sar.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emsr2index = {k: i for i, k in enumerate(activation_groups.keys())}\n",
    "index2emsr = {v: k for k, v in emsr2index.items()}\n",
    "weights = np.zeros(len(emsr2index))\n",
    "counts = {code: 0 for code in emsr2index.keys()}\n",
    "\n",
    "for sample in emsr2sar:\n",
    "    weights[emsr2index[sample.code]] += sample.num_tiles\n",
    "    counts[sample.code] += sample.num_tiles\n",
    "\n",
    "weights = smooth_weights(data=weights, clip=2000)\n",
    "print(len(weights), weights.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emsr_codes = list(activation_groups.keys())\n",
    "train_percent = 0.65  # it usually becomes 80% of the data, after tile count\n",
    "valid_percent = 0.12  # 10% of the train set\n",
    "\n",
    "train = np.random.choice(emsr_codes, int(len(emsr_codes) * train_percent), replace=False, p=weights)\n",
    "valid = np.random.choice(train, int(len(train) * valid_percent), replace=False, p=np.ones(len(train)) / len(train))\n",
    "train = [c for c in train if c not in valid]\n",
    "test = [c for c in emsr_codes if (c not in train and c not in valid)]\n",
    "\n",
    "train_tiles = sum([counts[code] for code in train])\n",
    "valid_tiles = sum([counts[code] for code in valid])\n",
    "test_tiles = sum([counts[code] for code in test])\n",
    "total = sum(list(counts.values()))\n",
    "\n",
    "print(f\"train: {train_tiles} ({train_tiles / float(total) * 100}%), val: {valid_tiles} ({valid_tiles / float(total) * 100}%), test: {test_tiles} ({test_tiles / float(total) * 100}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = []\n",
    "for code in df.code:\n",
    "    if code in train:\n",
    "        sets.append(\"train\")\n",
    "    elif code in valid:\n",
    "        sets.append(\"val\")\n",
    "    else:\n",
    "        sets.append(\"test\")\n",
    "splitdf = df.assign(set=sets, size=[0.1] * len(sets))\n",
    "print(len(train), len(valid), len(test), len(df))\n",
    "splitdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_mapbox(splitdf,\n",
    "                        lat=splitdf.lat,\n",
    "                        lon=splitdf.lon,\n",
    "                        color=\"set\",\n",
    "                        size=\"size\",\n",
    "                        size_max=5,\n",
    "                        hover_name=\"title\",\n",
    "                        zoom=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)\n",
    "print(valid)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in train:\n",
    "    valid_activations[code].subset = \"train\"\n",
    "\n",
    "for code in test:\n",
    "    valid_activations[code].subset = \"test\"\n",
    "\n",
    "for code in valid:\n",
    "    valid_activations[code].subset = \"val\"\n",
    "\n",
    "for code, act in valid_activations.items():\n",
    "    act.delineation = [Path(v).name for v in act.delineation]\n",
    "    assert act.subset is not None and act.subset in (\"train\", \"test\", \"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateTimeAwareEncoder(json.JSONEncoder):\n",
    "    def default(self, v):\n",
    "        if isinstance(v, datetime):\n",
    "            return (v.isoformat())\n",
    "        else:\n",
    "            return super().default(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dict()\n",
    "\n",
    "for k, v in valid_activations.items():\n",
    "    raw_act = v.dict()\n",
    "    raw_act[\"delineations\"] = raw_act.pop(\"delineation\")\n",
    "    raw_data[k] = raw_act\n",
    "\n",
    "with open(cfg.summary_file, \"w\") as file:\n",
    "    file.write(json.dumps(raw_data, indent=4, cls=DateTimeAwareEncoder))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61bd0401774e7981c2ad7ca0754761d58a145d15f3fee780bc248b1d208f4211"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
